We are given a matrix with R rows and C columns has cells with integer coordinates (r, c), where 0 <= r < R and 0 <= c < C.
Additionally, we are given a cell in that matrix with coordinates (r0, c0).
Return the coordinates of all cells in the matrix, sorted by their distance from (r0, c0) from smallest distance to largest distance.  
Here, the distance between two cells (r1, c1) and (r2, c2) is the Manhattan distance, |r1 - r2| + |c1 - c2|.  
(You may return the answer in any order that satisfies this condition.)

Input Description:
Four Integers R,C,r0,c0 as integers as input.(1<R,C,,r0,c0<100).

Output Description:
Print the distance between two cells (r1, c1) and (r2, c2).

Sample Input:
1 2 0 0

Sample Output:
[0, 0] [0, 1]

Explanation:
The distances from (r0, c0) to other cells are: [0,1]

Sample Input:
2 3 1 1

Sample Output:
[1, 1] [0, 1] [1, 0] [1, 2] [0, 0] [0, 2]

Sample Input:
3 4 0 1

Sample Output:
[0, 1] [0, 0] [0, 2] [1, 1] [0, 3] [1, 0] [1, 2] [2, 1] [1, 3] [2, 0] [2, 2] [2, 3]

Sample Input:
0 0 0 0

Sample Output:
[0, 0]

Sample Input:
2 2 1 1 

Sample Output:
[1, 1] [0, 1] [1, 0] [0, 0]

Sample Input:
3 1 2 1

Sample Output:
[2, 1] [2, 0] [1, 0] [0, 0]
